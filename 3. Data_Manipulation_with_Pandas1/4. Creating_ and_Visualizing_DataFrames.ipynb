{"cells":[{"source":"# Creating and Visualizing DataFrames","metadata":{},"cell_type":"markdown","id":"b9cc5349-ca31-4c5c-aba5-b747fd85229f"},{"source":"## Visualizing your data","metadata":{},"cell_type":"markdown","id":"531fb07d-aaac-4d07-9ec0-3a04a6b1f1ef"},{"source":"# Which avocado size is most popular?","metadata":{},"cell_type":"markdown","id":"8fe4cec7-133c-47d7-bde7-33acfd1d62cb"},{"source":"**Exercise**\n\n_Which avocado size is most popular?_\n\nAvocados are increasingly popular and delicious in guacamole and on toast. The Hass Avocado Board keeps track of avocado supply and demand across the USA, including the sales of three different sizes of avocado. In this exercise, you'll use a bar plot to figure out which size is the most popular.\n\nBar plots are great for revealing relationships between categorical (size) and numeric (number sold) variables, but you'll often have to manipulate your data first in order to get the numbers you need for plotting.\n\npandas has been imported as pd, and avocados is available.\n\n**Instructions**\n\n- Print the head of the avocados dataset. What columns are available?\n\n#Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n#Look at the first few rows of data\nprint(avocados.head())\n\n- For each avocado size group, calculate the total number sold, storing as nb_sold_by_size.\n\n#Get the total number of avocados sold of each size\nnb_sold_by_size = avocados.groupby(\"size\")[\"nb_sold\"].sum()\n\n- Create a bar plot of the number of avocados sold by size.\n\n#Create a bar plot of the number of avocados sold by size\nnb_sold_by_size.plot(x=\"size\", y=\"sold\", kind=\"bar\",title=\"Most popular\")\n\n- Show the plot.\n\n#Show the plot\nplt.show()\n\n![bar](bar.png)\n\nBedazzling bar plot! \nIt looks like small avocados were the most-purchased size, but large avocados were a close second.\n","metadata":{},"cell_type":"markdown","id":"6ae57fa2-0205-4948-aebd-770aa6e284cb"},{"source":"# Changes in sales over time","metadata":{},"cell_type":"markdown","id":"69773314-dd74-4e6a-9bfa-94255a20fd6d"},{"source":"**Exercise**\n\n_Changes in sales over time_\n\nLine plots are designed to visualize the relationship between two numeric variables, where each data values is connected to the next one. They are especially useful for visualizing the change in a number over time since each time point is naturally connected to the next time point. In this exercise, you'll visualize the change in avocado sales over three years.\n\npandas has been imported as pd, and avocados is available.\n\n**Instructions**\n\n- Get the total number of avocados sold on each date. The DataFrame has two rows for each date—one for organic, and one for conventional. Save this as nb_sold_by_date.\n\n#Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n#et _the total number of avocados sold on each date_\nnb_sold_by_date = avocados.groupby(\"date\")[\"nb_sold\"].sum()\n\n- Create a line plot of the number of avocados sold.\n\n#Create a line plot of the number of avocados sold by date\nnb_sold_by_date.plot(x=\"organic\", y=\"conventional\", kind=\"line\", title=\"The number of avocados sold\")\n\n- Show the plot.\n\n#Show the plot\nplt.show()\n\novely line plot! \nLine plots are great for visualizing something over time. Here, it looks like the number of avocados spikes around the same time each year.","metadata":{},"cell_type":"markdown","id":"f37a7266-6309-48d0-a829-ff68385f4092"},{"source":"# Avocado supply and demand","metadata":{},"cell_type":"markdown","id":"dde52867-5954-440f-abf3-6781ded08441"},{"source":"**Exercise**\n\n_Avocado supply and demand_\n\n_Scatter plots are ideal for visualizing relationships between numerical variables._ In this exercise, you'll compare the number of avocados sold to average price and see if they're at all related. If they're related, you may be able to use one number to predict the other.\n\nmatplotlib.pyplot has been imported as plt, pandas has been imported as pd, and avocados is available.\n\n**Instructions**\n\n- Create a scatter plot with nb_sold on the x-axis and avg_price on the y-axis. Title it \"Number of avocados sold vs. average price\".\n\n#Scatter plot of avg_price vs. nb_sold with title\navocados.plot(x=\"nb_sold\", y=\"avg_price\", kind=\"scatter\", title=\"Number of avocados sold vs. average price\")\n\n\n- Show the plot.\n\n#Show the plot\nplt.show()\n\nSuper scatter plot! \nIt looks like when more avocados are sold, prices go down. However, this doesn't mean that fewer sales causes higher prices - we can only tell that they're correlated with each other.","metadata":{},"cell_type":"markdown","id":"10bd9de4-dc15-42ab-8650-3860db364298"},{"source":"# Price of conventional vs. organic avocados","metadata":{},"cell_type":"markdown","id":"e9399068-04a2-41ff-9e0d-55c80156296d"},{"source":"**Exercise**\n\n_Price of conventional vs. organic avocados_\n\nCreating multiple plots for different subsets of data allows you to compare groups. In this exercise, you'll create multiple histograms to compare the prices of conventional and organic avocados.\n\nmatplotlib.pyplot has been imported as plt and pandas has been imported as pd.\n\n**Instructions 1/3**\n\n- Subset avocados for the conventional type, and the average price column. Create a histogram.\n\n#Histogram of conventional avg_price avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist()\n\n- Create a histogram of avg_price for organic type avocados.\n\n#Histogram of organic avg_price\navocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist()\n\n- Add a legend to your plot, with the names \"conventional\" and \"organic\".\n\n#Add a legend\nplt.legend([\"conventional\" , \"organic\"])\n\n- Show your plot.\n\n#Show the plot\nplt.show()\n\n**Instructions 2/3**\n\n- Modify your code to adjust the transparency of both histograms to 0.5 to see how much overlap there is between the two distributions.\n\n#Modify histogram transparency to 0.5 \navocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5)\n\n#Modify histogram transparency to 0.5\navocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5)\n\n#Add a legend\nplt.legend([\"conventional\", \"organic\"])\n\n#Show the plot\nplt.show()\n\n**Instructions 3/3**\n\n- Modify your code to use 20 bins in both histograms.\n\n#Modify bins to 20\navocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n\n#Modify bins to 20\navocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n\n#Add a legend\nplt.legend([\"conventional\", \"organic\"])\n\n#Show the plot\nplt.show()\n\nGreat layering! \nWe can see that on average, organic avocados are more expensive than conventional ones, but their price distributions have some overlap.","metadata":{},"cell_type":"markdown","id":"794f29b1-1f6e-46c3-99c9-392a000c2911"},{"source":"# Missing values","metadata":{},"cell_type":"markdown","id":"99702c43-c41b-4a33-8b18-05e06abf0004"},{"source":"## Finding missing values","metadata":{},"cell_type":"markdown","id":"9400cb2d-9da7-4ab6-af83-a3cf37643838"},{"source":"**Exercise**\n\n_Finding missing values_\n\nMissing values are everywhere, and you don't want them interfering with your work. Some functions ignore missing data by default, but that's not always the behavior you might want. Some functions can't handle missing values at all, so these values need to be taken care of before you can use them. If you don't know where your missing values are, or if they exist, you could make mistakes in your analysis. In this exercise, you'll determine if there are missing values in the dataset, and if so, how many.\n\npandas has been imported as pd and avocados_2016, a subset of avocados that contains only sales from 2016, is available.\n\n**Instructions**\n\n- Print a DataFrame that shows whether each value in avocados_2016 is missing or not.\n\n#Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n#Check individual values for missing values\nprint(avocados_2016.isna())\n\n<script.py> output:\n\n         date  avg_price  total_sold  small_sold  large_sold  xl_sold  total_bags_sold  small_bags_sold  large_bags_sold  xl_bags_sold\n    0   False      False       False       False       False    False            False            False            False         False\n    1   False      False       False       False       False    False            False            False            False         False\n    2   False      False       False       False        True    False            False            False            False         False\n    3   False      False       False       False       False    False            False            False            False         False\n    4   False      False       False       False       False     True            False            False            False         False\n    5   False      False       False        True       False    False            False            False            False         False\n    6   False      False       False       False       False    False            False            False            False         False\n    7   False      False       False       False        True    False            False            False            False         False\n    8   False      False       False       False       False    False            False            False            False         False\n    9   False      False       False       False       False    False            False            False            False         False\n    10  False      False       False       False        True    False            False            False            False         False\n    11  False      False       False       False       False    False            False            False            False         False\n    12  False      False       False       False       False    False            False            False            False         False\n    13  False      False       False       False       False    False            False            False            False         False\n    14  False      False       False       False       False    False            False            False            False         False\n    15  False      False       False       False        True    False            False            False            False         False\n    16  False      False       False       False       False     True            False            False            False         False\n    17  False      False       False       False       False    False            False            False            False         False\n    18  False      False       False       False       False    False            False            False            False         False\n    19  False      False       False       False        True    False            False            False            False         False\n    20  False      False       False       False       False    False            False            False            False         False\n    21  False      False       False       False       False    False            False            False            False         False\n    22  False      False       False       False       False    False            False            False            False         False\n    23  False      False       False       False       False    False            False            False            False         False\n    24  False      False       False       False       False    False            False            False            False         False\n    25  False      False       False       False       False    False            False            False            False         False\n    26  False      False       False       False       False    False            False            False            False         False\n    27  False      False       False       False       False    False            False            False            False         False\n    28  False      False       False       False       False    False            False            False            False         False\n    29  False      False       False       False       False    False            False            False            False         False\n    30  False      False       False       False       False     True            False            False            False         False\n    31  False      False       False       False       False    False            False            False            False         False\n    32  False      False       False       False       False     True            False            False            False         False\n    33  False      False       False       False       False    False            False            False            False         False\n    34  False      False       False       False       False    False            False            False            False         False\n    35  False      False       False       False       False    False            False            False            False         False\n    36  False      False       False        True       False    False            False            False            False         False\n    37  False      False       False       False        True    False            False            False            False         False\n    38  False      False       False       False       False    False            False            False            False         False\n    39  False      False       False       False       False    False            False            False            False         False\n    40  False      False       False        True       False    False            False            False            False         False\n    41  False      False       False       False       False    False            False            False            False         False\n    42  False      False       False       False       False    False            False            False            False         False\n    43  False      False       False       False       False    False            False            False            False         False\n    44  False      False       False        True       False    False            False            False            False         False\n    45  False      False       False       False       False    False            False            False            False         False\n    46  False      False       False       False       False    False            False            False            False         False\n    47  False      False       False       False       False    False            False            False            False         False\n    48  False      False       False       False       False    False            False            False            False         False\n    49  False      False       False       False       False    False            False            False            False         False\n    50  False      False       False        True       False    False            False            False            False         False\n    51  False      False       False        True       False    False            False            False            False         False\n\n- Print a summary that shows whether any value in each column is missing or not.\n\n#Check each column for missing values\nprint(avocados_2016.isna().any())\n\n<script.py> output:\n\n    date               False\n    avg_price          False\n    total_sold         False\n    small_sold          True\n    large_sold          True\n    xl_sold             True\n    total_bags_sold    False\n    small_bags_sold    False\n    large_bags_sold    False\n    xl_bags_sold       False\n    dtype: bool\n\n- Create a bar plot of the total number of missing values in each column.\n\n#Bar plot of missing values by variable\nimport matplotlib.pyplot as plt\navocados_2016.isna().sum().plot(kind=\"bar\")\n\n#Show plot\nplt.show()\n","metadata":{},"cell_type":"markdown","id":"f5edc0bf-b3fb-4456-8946-a82a7e5e47fe"},{"source":"## _Removing missing values_","metadata":{},"cell_type":"markdown","id":"f3bd0ed8-36fb-4b2f-9129-9e164227baaa"},{"source":"**Exercise**\n\n_Removing missing values_\n\nNow that you know there are some missing values in your DataFrame, you have a few options to deal with them. One way is to remove them from the dataset completely. In this exercise, you'll remove missing values by removing all rows that contain missing values.\n\npandas has been imported as pd and avocados_2016 is available.\n\n**Instructions**\n\n- Remove the rows of avocados_2016 that contain missing values and store the remaining rows in avocados_complete.\n\n#Remove rows with missing values\navocados_complete = avocados_2016.dropna()\n\n\n- Verify that all missing values have been removed from avocados_complete. Calculate each column that has NAs and print.\n\n#Check if any columns contain missing values\nprint(avocados_complete.isna().any())\n\n<script.py> output:\n\n    date               False\n    avg_price          False\n    total_sold         False\n    small_sold         False\n    large_sold         False\n    xl_sold            False\n    total_bags_sold    False\n    small_bags_sold    False\n    large_bags_sold    False\n    xl_bags_sold       False\n    dtype: bool\n    \n\nDelightful dropping! \nRemoving observations with missing values is a quick and dirty way to deal with missing data, but this can introduce bias to your data if the values are not missing at random.","metadata":{},"cell_type":"markdown","id":"f8b659db-774c-4dcf-9b75-15bdadeaef33"},{"source":"## _Replacing missing values_","metadata":{},"cell_type":"markdown","id":"d69e038a-2119-4c75-83d5-6406d9863896"},{"source":"**Exercise**\n\n_Replacing missing values_\n\nAnother way of handling missing values is to replace them _all with the same value_. For numerical variables, one option is to replace values with 0— you'll do this here. \nHowever, when you replace missing values, you make assumptions about what a missing value means. \nIn this case, you will assume that a missing number sold means that no sales for that avocado type were made that week.\n\nIn this exercise, you'll see how replacing missing values can affect the distribution of a variable using histograms. You can plot histograms for multiple variables at a time as follows:\n\ndogs[[\"height_cm\", \"weight_kg\"]].hist()\n\npandas has been imported as pd and matplotlib.pyplot has been imported as plt. The avocados_2016 dataset is available.\n\n**Instructions 1/2**\n\n- A list has been created, cols_with_missing, containing the names of columns with missing values: \"small_sold\", \"large_sold\", and \"xl_sold\".\n\n#List the columns with missing values\ncols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\n\n- Create a histogram of those columns.\n\n#Create histograms showing the distributions cols_with_missing\navocados_2016[cols_with_missing].hist()\n\n- Show the plot.\n\n#Show the plot\nplt.show()\n\n\n**Instructions 2/2**\n\n- Replace the missing values of avocados_2016 with 0s and store the result as avocados_filled.\n\n#From previous step\ncols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\n\navocados_2016[cols_with_missing].hist()\n\nplt.show()\n\n#Fill in missing values with 0\navocados_filled = avocados_2016.fillna(0)\n\n- Create a histogram of _the cols_with_missing_ columns of avocados_filled.\n\n#Create histograms of the filled columns\navocados_filled[cols_with_missing].hist()\nplt.show()\n\n#Show the plot\nplt.show()\n\nFabulous filling! \nNotice how the distribution has changed shape after replacing missing values with zeros.\n","metadata":{},"cell_type":"markdown","id":"87c268bd-831b-4053-aa5c-d391efee8cdd"},{"source":"# Creating DataFrames","metadata":{},"cell_type":"markdown","id":"c8ffc982-18c8-4ead-a074-e17928ab0245"},{"source":"## _List of dictionaries_","metadata":{},"cell_type":"markdown","id":"faecc245-3a42-43ee-9120-b8fdbef23ae7"},{"source":"**Exercise**\n\n_List of dictionaries_\n\nYou recently got some new avocado data from 2019 that you'd like to put in a DataFrame using the list of dictionaries method. Remember that with this method, you go through the data row by row.\n\ndate\tsmall_sold\tlarge_sold\n\"2019-11-03\"\t10376832\t7835071\n\"2019-11-10\"\t10717154\t8561348\npandas as pd is imported.\n\n**Instructions**\n\n- Create a list of dictionaries with the new data called avocados_list.\n\n#Create a list of dictionaries with new data\n\navocados_list = [\n    {\"date\": \"2019-11-03\", \"small_sold\": 10376832, \"large_sold\": 7835071},\n    {\"date\": \"2019-11-10\", \"small_sold\": 10717154, \"large_sold\": 8561348},\n]\n\n- Convert the list into a DataFrame called avocados_2019.\n\n#Convert list into DataFrame\n\navocados_2019 = pd.DataFrame(avocados_list)\n\n\n- Print your new DataFrame.\n\n#Print the new DataFrame\nprint(avocados_2019)\n\n<script.py> output:\n\n             date  small_sold  large_sold\n    0  2019-11-03    10376832     7835071\n    1  2019-11-10    10717154     8561348\n \nLovely work with the list-of-dictionaries! \nThe list-of-dictionaries method creates DataFrames row-by-row.","metadata":{},"cell_type":"markdown","id":"e45dd52d-531f-4adb-af1a-6700033a5411"},{"source":"## Dictionary of lists","metadata":{},"cell_type":"markdown","id":"37c922b8-0d49-48c2-8cff-73dbc49510e9"},{"source":"**Exercise**\n\n_Dictionary of lists_\n\nSome more data just came in! This time, you'll use the dictionary of lists method, parsing the data column by column.\n\ndate\tsmall_sold\tlarge_sold\n\"2019-11-17\"\t10859987\t7674135\n\"2019-12-01\"\t9291631\t6238096\npandas as pd is imported.\n\n**Instructions**\n\n- Create a dictionary of lists with the new data called avocados_dict.\n\n#Create a dictionary of lists with new data\navocados_dict = {\n  \"date\": [\"2019-11-17\", \"2019-12-01\"],\n  \"small_sold\": [10859987, 9291631],\n  \"large_sold\": [7674135,6238096]\n}\n\n- Convert the dictionary to a DataFrame called avocados_2019.\n\n#Convert dictionary into DataFrame\navocados_2019 = pd.DataFrame(avocados_dict)\n\n- Print your new DataFrame\n\n#Print the new DataFrame\nprint(avocados_2019)\n\n<script.py> output:\n\n             date  small_sold  large_sold\n    0  2019-11-17    10859987     7674135\n    1  2019-12-01     9291631     \n\nDelightful dictionary-of-lists usage! \nThe list-of-dictionaries method creates DataFrames column-by-column.","metadata":{},"cell_type":"markdown","id":"a2475071-ccdb-4bcd-95b4-7904e23de15f"},{"source":"## CSV to DataFrame","metadata":{},"cell_type":"markdown","id":"0a6c9bcc-3066-4193-b07b-27d2668b4e29"},{"source":"**Exercise**\n\n_CSV to DataFrame_\n\nYou work for an airline, and your manager has asked you to do a competitive analysis and see how often passengers flying on other airlines are involuntarily bumped from their flights. You got a CSV file (airline_bumping.csv) from the Department of Transportation containing data on passengers that were involuntarily denied boarding in 2016 and 2017, but it doesn't have the exact numbers you want. In order to figure this out, you'll need to get the CSV into a pandas DataFrame and do some manipulation!\n\npandas is imported for you as pd. \"airline_bumping.csv\" is in your working directory.\n\n**Instructions 1/4**\n\n- _Read the CSV file_ \"airline_bumping.csv\" and store it as a DataFrame called airline_bumping.\n\n#Read CSV as DataFrame called airline_bumping\nairline_bumping = pd.read_csv(\"airline_bumping.csv\")\n\n- Print the first few rows of airline_bumping\n\n#Take a look at the DataFrame\nprint(airline_bumping.head())\n\n<script.py> output:\n\n                 airline  year  nb_bumped  total_passengers\n    0    DELTA AIR LINES  2017        679          99796155\n    1     VIRGIN AMERICA  2017        165           6090029\n    2    JETBLUE AIRWAYS  2017       1475          27255038\n    3    UNITED AIRLINES  2017       2067          70030765\n    4  HAWAIIAN AIRLINES  2017         92           8422734\n    \n\n**Instructions 2/4**\n\n- For each airline group, select the nb_bumped, and total_passengers columns, and calculate the sum (for both years). Store this as airline_totals.\n\n#  From previous step\nairline_bumping = pd.read_csv(\"airline_bumping.csv\")\nprint(airline_bumping.head())\n\n#For each airline, select nb_bumped and total_passengers and sum\nairline_totals = airline_bumping.groupby(\"airline\")[[\"nb_bumped\" , \"total_passengers\"]].sum\n\n<script.py> output:\n\n             airline  year  nb_bumped  total_passengers\n0    DELTA AIR LINES  2017        679          99796155\n1     VIRGIN AMERICA  2017        165           6090029\n2    JETBLUE AIRWAYS  2017       1475          27255038\n3    UNITED AIRLINES  2017       2067          70030765\n4  HAWAIIAN AIRLINES  2017         92           8422734\n\n**Instructions 3/4**\n\n- Create a new column of airline_totals called bumps_per_10k, which is the number of passengers bumped per 10,000 passengers in 2016 and 2017.\n\n#From previous steps\nairline_bumping = pd.read_csv(\"airline_bumping.csv\")\nprint(airline_bumping.head())\nairline_totals = airline_bumping.groupby(\"airline\")[[\"nb_bumped\", \"total_passengers\"]].sum()\n\n#Create new col, bumps_per_10k: no. of bumps per 10k passengers for each airline\nairline_totals[\"bumps_per_10k\"] = airline_totals[\"nb_bumped\"] / airline_totals[\"total_passengers\"] * 10000\n\n<script.py> output:\n\n                 airline  year  nb_bumped  total_passengers\n    0    DELTA AIR LINES  2017        679          99796155\n    1     VIRGIN AMERICA  2017        165           6090029\n    2    JETBLUE AIRWAYS  2017       1475          27255038\n    3    UNITED AIRLINES  2017       2067          70030765\n    4  HAWAIIAN AIRLINES  2017         92           8422734\n\n**Instructions 4/4**\n\n- Print airline_totals to see the results of your manipulations.\n\n#From previous steps\nairline_bumping = pd.read_csv(\"airline_bumping.csv\")\nprint(airline_bumping.head())\nairline_totals = airline_bumping.groupby(\"airline\")[[\"nb_bumped\", \"total_passengers\"]].sum()\nairline_totals[\"bumps_per_10k\"] = airline_totals[\"nb_bumped\"] / airline_totals[\"total_passengers\"] * 10000\n\n#Print airline_totals\nprint(airline_totals)\n\n<script.py> output:\n\n                     nb_bumped  total_passengers  bumps_per_10k\nairline                                                        \nALASKA AIRLINES           1392          36543121          0.381\nAMERICAN AIRLINES        11115         197365225          0.563\nDELTA AIR LINES           1591         197033215          0.081\nEXPRESSJET AIRLINES       3326          27858678          1.194\nFRONTIER AIRLINES         1228          22954995          0.535\nHAWAIIAN AIRLINES          122          16577572          0.074\nJETBLUE AIRWAYS           3615          53245866          0.679\nSKYWEST AIRLINES          3094          47091737          0.657\nSOUTHWEST AIRLINES       18585         228142036          0.815\nSPIRIT AIRLINES           2920          32304571          0.904\nUNITED AIRLINES           4941         134468897          0.367\nVIRGIN AMERICA             242          12017967          0.201\n\nMasterful manipulation! \nNow you'll need to export this so you can share it with others.","metadata":{},"cell_type":"markdown","id":"e7d887f4-ca4b-46a0-9bfc-51cd57cf1cf1"},{"source":"**Exercise**\n\n_DataFrame to CSV_\n\nYou're almost there! To make things easier to read, you'll need to sort the data and export it to CSV so that your colleagues can read it.\n\npandas as pd has been imported for you.\n\n**Instructions**\n\n- Sort airline_totals by the values of bumps_per_10k from highest to lowest, storing as airline_totals_sorted.\n\n#Create airline_totals_sorted\nairline_totals_sorted = airline_totals.sort_values(by=\"bumps_per_10k\", ascending=False)\n\n- Print your sorted DataFrame.\n\n#Print airline_totals_sorted\nprint(airline_totals_sorted)\n\n- Save the sorted DataFrame as a CSV called \"airline_totals_sorted.csv\".\n\n#Save as airline_totals_sorted.csv\nairline_totals_sorted.to_csv(\"airline_totals_sorted.csv\")\n\n<script.py> output:\n\n                         nb_bumped  total_passengers  bumps_per_10k\n    airline                                                        \n    EXPRESSJET AIRLINES       3326          27858678          1.194\n    SPIRIT AIRLINES           2920          32304571          0.904\n    SOUTHWEST AIRLINES       18585         228142036          0.815\n    JETBLUE AIRWAYS           3615          53245866          0.679\n    SKYWEST AIRLINES          3094          47091737          0.657\n    AMERICAN AIRLINES        11115         197365225          0.563\n    FRONTIER AIRLINES         1228          22954995          0.535\n    ALASKA AIRLINES           1392          36543121          0.381\n    UNITED AIRLINES           4941         134468897          0.367\n    VIRGIN AMERICA             242          12017967          0.201\n    DELTA AIR LINES           1591         197033215          0.081\n    HAWAIIAN AIRLINES          122          16577572          0.074\n    \nExcellent exporting! \nNow you can share these insights about your competitors with your team.","metadata":{},"cell_type":"markdown","id":"cad01091-9860-4a2b-8018-a3116709c9af"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}