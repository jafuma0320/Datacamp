{"cells":[{"source":"## _Inspecting a DataFrame_","metadata":{},"cell_type":"markdown","id":"c2420d9e-4328-404f-93a6-49c0388697c2"},{"source":"**Exercise**\n\n_Inspecting a DataFrame_\n\nWhen you get a new DataFrame to work with, the first thing you need to do is explore it and see what it contains. There are several useful methods and attributes for this.\n\n- .head() returns the first few rows (the “head” of the DataFrame).\n- .info() shows information on each of the columns, such as the data type and number of missing values.\n- .shape returns the number of rows and columns of the DataFrame.\n- .describe() calculates a few summary statistics for each column.\n\n_homelessness_ is a DataFrame containing estimates of homelessness in each U.S. state in 2018. The individual column is the number of homeless individuals not part of a family with children. The family_members column is the number of homeless individuals part of a family with children. The state_pop column is the state's total population.\n\npandas is imported for you.\n\n**Instructions 1/4**\n\nPrint the head of the homelessness DataFrame.\n\n#Print the head of the homelessness dataframe\n\nprint(homelessness.head())\n\n               region       state  individuals  family_members  state_pop\n0  East South Central     Alabama       2570.0           864.0    4887681\n1             Pacific      Alaska       1434.0           582.0     735139\n2            Mountain     Arizona       7259.0          2606.0    7158024\n3  West South Central    Arkansas       2280.0           432.0    3009733\n4             Pacific  California     109008.0         20964.0   39461588\n\n#Print information about homelessness\n\nprint(homelessness.info())\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 51 entries, 0 to 50\nData columns (total 5 columns):\n N.   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   region          51 non-null     object \n 1   state           51 non-null     object \n 2   individuals     51 non-null     float64\n 3   family_members  51 non-null     float64\n 4   state_pop       51 non-null     int64  \ndtypes: float64(2), int64(1), object(2)\nmemory usage: 2.4+ KB\nNone\n\n#Print the shape of homelessness\n\nprint(homelessness.shape)\n\n(51, 5)\n\n#Print a description of homelessness\n\nprint(homelessness.describe())\n\n        individuals  family_members  state_pop\n    count       51.000          51.000  5.100e+01\n    mean      7225.784        3504.882  6.406e+06\n    std      15991.025        7805.412  7.327e+06\n    min        434.000          75.000  5.776e+05\n    25%       1446.500         592.000  1.777e+06\n    50%       3082.000        1482.000  4.461e+06\n    75%       6781.500        3196.000  7.341e+06\n    max     109008.000       52070.000  3.946e+07\n\nInsightful inspecting!\nYou can see that the average number of homeless individuals in each state is about 7226. Let's explore the DataFrame further.","metadata":{},"cell_type":"markdown","id":"5b5cf217-0943-4f45-876f-9d202c12c291"},{"source":"## _Parts of a DataFrame_","metadata":{},"cell_type":"markdown","id":"617ca584-a6e0-4948-b889-0b26abb91df1"},{"source":"**Exercise**\n\n_Parts of a DataFrame_\n\nTo better understand DataFrame objects, it's useful to know that they consist of three components, stored as attributes:\n\n- .values: A two-dimensional NumPy array of values.\n- .columns: An index of columns: the column names.\n- .index: An index for the rows: either row numbers or row names.\n\nYou can usually think of indexes as a list of strings or numbers, though the pandas Index data type allows for more sophisticated options. (These will be covered later in the course.)\n\nhomelessness is available.\n\n**Instructions**\n\n- Import pandas using the alias pd.\n- Print a 2D NumPy array of the values in homelessness.\n- Print the column names of homelessness.\n- Print the index of homelessness.\n\n#Output\n#Import pandas using the alias pd\nimport pandas as pd\n\n#Print the values of homelessness\nprint(homelessness.values)\n\n[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n     ['Pacific' 'Alaska' 1434.0 582.0 735139]\n     ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n     ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n     ['Pacific' 'California' 109008.0 20964.0 39461588]\n     ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n     ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n     ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n     ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n     ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n     ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n     ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n     ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n     ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n     ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n     ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n     ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n     ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n     ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n     ['New England' 'Maine' 1450.0 1066.0 1339057]\n     ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n     ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n     ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n     ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n     ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n     ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n     ['Mountain' 'Montana' 983.0 422.0 1060665]\n     ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n     ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n     ['New England' 'New Hampshire' 835.0 615.0 1353465]\n     ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n     ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n     ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n     ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n     ['West North Central' 'North Dakota' 467.0 75.0 758080]\n     ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n     ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n     ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n     ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n     ['New England' 'Rhode Island' 747.0 354.0 1058287]\n     ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n     ['West North Central' 'South Dakota' 836.0 323.0 878698]\n     ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n     ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n     ['Mountain' 'Utah' 1904.0 972.0 3153550]\n     ['New England' 'Vermont' 780.0 511.0 624358]\n     ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n     ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n     ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n     ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n     ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n\n\n#Print the column index of homelessness\nprint(homelessness.columns)\n\nIndex(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n\n#Print the row index of homelessness\nprint(homelessness.index)\n\nInt64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n                49, 50],\n               dtype='int64')\n\nDynamite DataFrame dissection! \nDataFrames have three components: values, a column index, and a row index.\n\n","metadata":{},"cell_type":"markdown","id":"7a7f0c8a-c4f1-4be1-8f6d-0790358c704f"},{"source":"# Sorting and subsetting","metadata":{},"cell_type":"markdown","id":"0242549a-a9f9-442a-8705-32cdab89f3ac"},{"source":"## _Sorting rows_","metadata":{},"cell_type":"markdown","id":"c5075d11-01ca-4463-b5fe-53f844f00c67"},{"source":"**Exercise**\n\n_Sorting rows_\n\nFinding interesting bits of data in a DataFrame is often easier if you change the order of the rows. You can sort the rows by passing a column name to .sort_values().\n\nIn cases where rows have the same value (this is common if you sort on a categorical variable), you may wish to break the ties by sorting on another column. You can sort on multiple columns in this way by passing a list of column names.\n\nSort on …\tSyntax\none column\tdf.sort_values(\"breed\")\nmultiple columns\tdf.sort_values([\"breed\", \"weight_kg\"])\nBy combining .sort_values() with .head(), you can answer questions in the form, \"What are the top cases where…?\".\n\nhomelessness is available and pandas is loaded as pd.\n\n**Instructions 1/3**\n\nSort homelessness by the number of homeless individuals, from smallest to largest, and save this as homelessness_ind.\nPrint the head of the sorted DataFrame.\nSort homelessness by the number of homeless family_members in descending order, and save this as homelessness_fam.\nPrint the head of the sorted DataFrame.\nSort homelessness first by region (ascending), and then by number of family members (descending). Save this as homelessness_reg_fam.\nPrint the head of the sorted DataFrame.\n\n_Instructions 1/3_\n\n- Sort homelessness by the number of homeless individuals, from smallest to largest, and save this as homelessness_ind.\n- Print the head of the sorted DataFrame.\n\nAnswer:\n#Sort homelessness by individuals\nhomelessness_ind = homelessness.sort_values(\"individuals\")\n\n#Print the top few rows\nprint(homelessness_ind.head())\n\n                region         state  individuals  family_members  state_pop\n50            Mountain       Wyoming        434.0           205.0     577601\n34  West North Central  North Dakota        467.0            75.0     758080\n7       South Atlantic      Delaware        708.0           374.0     965479\n39         New England  Rhode Island        747.0           354.0    1058287\n45         New England       Vermont        780.0           511.0     624358\n\n_Instructions 2/3_\n\nSort homelessness by the number of homeless family_members in descending order, and save this as homelessness_fam.\nPrint the head of the sorted DataFrame.\n\n#Sort homelessness by descending family members\nhomelessness_fam = homelessness.sort_values(\"family_members\" , ascending = False)\n\n#Print the top few rows\nprint(homelessness_fam.head())\n\n                region          state  individuals  family_members  state_pop\n32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n4              Pacific     California     109008.0         20964.0   39461588\n21         New England  Massachusetts       6811.0         13257.0    6882635\n9       South Atlantic        Florida      21443.0          9587.0   21244317\n43  West South Central          Texas      19199.0          6111.0   28628666\n\nInstructions 3/3\n\nSort homelessness first by region (ascending), and then by number of family members (descending). Save this as homelessness_reg_fam.\nPrint the head of the sorted DataFrame.\n\n                region      state  individuals  family_members  state_pop\n13  East North Central   Illinois       6752.0          3891.0   12723071\n35  East North Central       Ohio       6929.0          3320.0   11676341\n22  East North Central   Michigan       5209.0          3142.0    9984072\n49  East North Central  Wisconsin       2740.0          2167.0    5807406\n14  East North Central    Indiana       3776.0          1482.0    6695497","metadata":{},"cell_type":"markdown","id":"44c5e442-4fed-45be-8acb-61d2eec4c00d"},{"source":"## Subsetting columns","metadata":{},"cell_type":"markdown","id":"921b0cbd-c6fc-4452-b705-4594e67b726a"},{"source":"**Exercise**\n\nSubsetting columns\n\nWhen working with data, you may not need all of the variables in your dataset. Square brackets ([]) can be used to select only the columns that matter to you in an order that makes sense to you. To select only \"col_a\" of the DataFrame df, use\n\ndf[\"col_a\"]\nTo select \"col_a\" and \"col_b\" of df, use\n\ndf[[\"col_a\", \"col_b\"]]\nhomelessness is available and pandas is loaded as pd.\n\nInstructions 1/3\n\nCreate a DataFrame called individuals that contains only the individuals column of homelessness.\nPrint the head of the result.\n\n#Select the individuals column\nindividuals = homelessness[\"individuals\"]\n\n#Print the head of the result\nprint(individuals.head())\n\n#Print the head of the result\nprint(individuals.head())\n0      2570.0\n1      1434.0\n2      7259.0\n3      2280.0\n4    109008.0\nName: individuals, dtype: float64\n\nInstructions 2/3\n\nCreate a DataFrame called state_fam that contains only the state and family_members columns of homelessness, in that order.\nPrint the head of the result.\n\n#Select the state and family_members columns\nstate_fam = homelessness[[\"state\" , \"family_members\"]]\n\n#Print the head of the result\nprint(state_fam.head())\n\n<script.py> output:\n    0      2570.0\n    1      1434.0\n    2      7259.0\n    3      2280.0\n    4    109008.0\n    Name: individuals, dtype: float64\n\nInstructions 3/3\n\nCreate a DataFrame called ind_state that contains the individuals and state columns of homelessness, in that order.\nPrint the head of the result.\n\n#Select only the individuals and state columns, in that order\nind_state = homelessness[[\"individuals\" , \"state\"]]\n\n#Print the head of the result\nprint(ind_state.head())\n\n<script.py> output:\n            state  family_members\n    0     Alabama           864.0\n    1      Alaska           582.0\n    2     Arizona          2606.0\n    3    Arkansas           432.0\n    4  California         20964.0\n\nRadical reordering! Selecting and reordering columns can make data easier to work with.","metadata":{},"cell_type":"markdown","id":"a6b14e66-08b7-4ff2-bea9-204843e5488a"},{"source":"## Subsetting rows","metadata":{},"cell_type":"markdown","id":"800bc36b-ca4e-4012-87cf-44a0caa45512"},{"source":"**Exercise**\n\n_Subsetting rows_\n\nA large part of data science is about finding which bits of your dataset are interesting. One of the simplest techniques for this is to find a subset of rows that match some criteria. This is sometimes known as filtering rows or selecting rows.\n\nThere are many ways to subset a DataFrame, perhaps the most common is to use relational operators to return True or False for each row, then pass that inside square brackets.\n\ndogs[dogs[\"height_cm\"] > 60]\ndogs[dogs[\"color\"] == \"tan\"]\n\nYou can filter for multiple conditions at once by using the \"bitwise and\" operator, &.\n\ndogs[(dogs[\"height_cm\"] > 60) & (dogs[\"color\"] == \"tan\")]\nhomelessness is available and pandas is loaded as pd.\n\n_Instructions 1/3_\n\nFilter homelessness for cases where the number of individuals is greater than ten thousand, assigning to ind_gt_10k. View the printed result.\n\n#Filter for rows where individuals is greater than 10000\nind_gt_10k = homelessness[homelessness[\"individuals\"] > 10000]\n\n#See the result\nprint(ind_gt_10k)\n\n\n                region       state  individuals  family_members  state_pop\n4              Pacific  California     109008.0         20964.0   39461588\n9       South Atlantic     Florida      21443.0          9587.0   21244317\n32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n37             Pacific      Oregon      11139.0          3337.0    4181886\n43  West South Central       Texas      19199.0          6111.0   28628666\n47             Pacific  Washington      16424.0          5880.0    7523869\n\n_Instructions 2/3_\n\nFilter homelessness for cases where the USA Census region is \"Mountain\", assigning to mountain_reg. View the printed result.\n\n#Filter for rows where region is Mountain\nmountain_reg = homelessness[homelessness[\"region\"] == \"Mountain\"]\n\n#See the result\nprint(mountain_reg)\n\n<script.py> output:\n\n                    region       state  individuals  family_members  state_pop\n    4              Pacific  California     109008.0         20964.0   39461588\n    9       South Atlantic     Florida      21443.0          9587.0   21244317\n    32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n    37             Pacific      Oregon      11139.0          3337.0    4181886\n    43  West South Central       Texas      19199.0          6111.0   28628666\n    47             Pacific  Washington      16424.0          5880.0    7523869\n\n_Instructions 3/3_\n\nFilter homelessness for cases where the number of family_members is less than one thousand and the region is \"Pacific\", assigning to fam_lt_1k_pac. View the printed result.\n\n#Filter for rows where family_members is less than 1000 and region is Pacific\nfam_lt_1k_pac = homelessness[(homelessness[\"family_members\"] < 1000) & (homelessness[\"region\"] == \"Pacific\")]\n\n#See the result\nprint(fam_lt_1k_pac)\n\n#See the result\nprint(fam_lt_1k_pac)\n    region   state  individuals  family_members  state_pop\n1  Pacific  Alaska       1434.0           582.0     735139\n\nSuperb subsetting! Using square brackets plus logical conditions is often the most powerful way of identifying interesting rows of data.","metadata":{},"cell_type":"markdown","id":"78022044-6c27-4675-b84e-9dc011a6112b"},{"source":"**Exercise**\n\nSubsetting rows by categorical variables\nSubsetting data based on a categorical variable often involves using the \"or\" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones.\n\ncolors = [\"brown\", \"black\", \"tan\"]\ncondition = dogs[\"color\"].isin(colors)\ndogs[condition]\nhomelessness is available and pandas is loaded as pd.\n\nInstructions 1/2\n\nFilter homelessness for cases where the USA census region is \"South Atlantic\" or it is \"Mid-Atlantic\", assigning to south_mid_atlantic. View the printed result.\n\n#Subset for rows in South Atlantic or Mid-Atlantic regions\nsouth_mid_atlantic = homelessness[(homelessness[\"region\"] == \"South Atlantic\") | (homelessness[\"region\"] == \"Mid-Atlantic\")]\n\n            region                 state  individuals  family_members  state_pop\n7   South Atlantic              Delaware        708.0           374.0     965479\n8   South Atlantic  District of Columbia       3770.0          3134.0     701547\n9   South Atlantic               Florida      21443.0          9587.0   21244317\n10  South Atlantic               Georgia       6943.0          2556.0   10511131\n20  South Atlantic              Maryland       4914.0          2230.0    6035802\n30    Mid-Atlantic            New Jersey       6048.0          3350.0    8886025\n32    Mid-Atlantic              New York      39827.0         52070.0   19530351\n33  South Atlantic        North Carolina       6451.0          2817.0   10381615\n38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   12800922\n40  South Atlantic        South Carolina       3082.0           851.0    5084156\n46  South Atlantic              Virginia       3928.0          2047.0    8501286\n48  South Atlantic         West Virginia       1021.0           222.0    1804291\n\n\nInstructions 2/2\n\nFilter homelessness for cases where the USA census state is in the list of Mojave states, canu, assigning to mojave_homelessness. View the printed result.\n\n#The Mojave Desert states\ncanu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n\n#Filter for rows in the Mojave Desert states\nmojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n\n#See the result\nprint(mojave_homelessness)\n\n                region                 state  individuals  family_members  state_pop\n    7   South Atlantic              Delaware        708.0           374.0     965479\n    8   South Atlantic  District of Columbia       3770.0          3134.0     701547\n    9   South Atlantic               Florida      21443.0          9587.0   21244317\n    10  South Atlantic               Georgia       6943.0          2556.0   10511131\n    20  South Atlantic              Maryland       4914.0          2230.0    6035802\n    30    Mid-Atlantic            New Jersey       6048.0          3350.0    8886025\n    32    Mid-Atlantic              New York      39827.0         52070.0   19530351\n    33  South Atlantic        North Carolina       6451.0          2817.0   10381615\n    38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   12800922\n    40  South Atlantic        South Carolina       3082.0           851.0    5084156\n    46  South Atlantic              Virginia       3928.0          2047.0    8501286\n    48  South Atlantic         West Virginia       1021.0           222.0    1804291\n    \nSuccess _is in_ the air! \nUsing .isin() makes subsetting categorical variables a breeze.","metadata":{},"cell_type":"markdown","id":"39d560da-af92-43be-b925-bae65073ddf8"},{"source":"# New Columns","metadata":{},"cell_type":"markdown","id":"58f0a34f-db22-457d-9d3e-d57327c4ed8d"},{"source":"**Exercise**\n\n_Adding new columns_\n\nYou aren't stuck with just the data you are given. Instead, you can add new columns to a DataFrame. This has many names, such as transforming, mutating, and feature engineering.\n\nYou can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units.\n\nhomelessness is available and pandas is loaded as pd.\n\n**Instructions**\n\n- Add a new column to homelessness, named total, containing the sum of the individuals and family_members columns.\n\n#Add total col as sum of individuals and family_members\nhomelessness[\"total\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"]\n\n- Add another column to homelessness, named p_individuals, containing the proportion of homeless people in each state who are individuals.\n\n#Add p_individuals col as proportion of total that are individuals\nhomelessness[\"p_individuals\"] = homelessness[\"individuals\"] / homelessness[\"total\"]\n\n#See the result\nprint(homelessness)\n\n                region                 state  individuals  family_members  state_pop     total  p_individuals\n0   East South Central               Alabama       2570.0           864.0    4887681    3434.0          0.748\n1              Pacific                Alaska       1434.0           582.0     735139    2016.0          0.711\n2             Mountain               Arizona       7259.0          2606.0    7158024    9865.0          0.736\n3   West South Central              Arkansas       2280.0           432.0    3009733    2712.0          0.841\n4              Pacific            California     109008.0         20964.0   39461588  129972.0          0.839\n5             Mountain              Colorado       7607.0          3250.0    5691287   10857.0          0.701\n6          New England           Connecticut       2280.0          1696.0    3571520    3976.0          0.573\n7       South Atlantic              Delaware        708.0           374.0     965479    1082.0          0.654\n8       South Atlantic  District of Columbia       3770.0          3134.0     701547    6904.0          0.546\n9       South Atlantic               Florida      21443.0          9587.0   21244317   31030.0          0.691\n10      South Atlantic               Georgia       6943.0          2556.0   10511131    9499.0          0.731\n11             Pacific                Hawaii       4131.0          2399.0    1420593    6530.0          0.633\n12            Mountain                 Idaho       1297.0           715.0    1750536    2012.0          0.645\n13  East North Central              Illinois       6752.0          3891.0   12723071   10643.0          0.634\n14  East North Central               Indiana       3776.0          1482.0    6695497    5258.0          0.718\n15  West North Central                  Iowa       1711.0          1038.0    3148618    2749.0          0.622\n16  West North Central                Kansas       1443.0           773.0    2911359    2216.0          0.651\n17  East South Central              Kentucky       2735.0           953.0    4461153    3688.0          0.742\n18  West South Central             Louisiana       2540.0           519.0    4659690    3059.0          0.830\n19         New England                 Maine       1450.0          1066.0    1339057    2516.0          0.576\n20      South Atlantic              Maryland       4914.0          2230.0    6035802    7144.0          0.688\n21         New England         Massachusetts       6811.0         13257.0    6882635   20068.0          0.339\n22  East North Central              Michigan       5209.0          3142.0    9984072    8351.0          0.624\n23  West North Central             Minnesota       3993.0          3250.0    5606249    7243.0          0.551\n24  East South Central           Mississippi       1024.0           328.0    2981020    1352.0          0.757\n25  West North Central              Missouri       3776.0          2107.0    6121623    5883.0          0.642\n26            Mountain               Montana        983.0           422.0    1060665    1405.0          0.700\n27  West North Central              Nebraska       1745.0           676.0    1925614    2421.0          0.721\n28            Mountain                Nevada       7058.0           486.0    3027341    7544.0          0.936\n29         New England         New Hampshire        835.0           615.0    1353465    1450.0          0.576\n30        Mid-Atlantic            New Jersey       6048.0          3350.0    8886025    9398.0          0.644\n31            Mountain            New Mexico       1949.0           602.0    2092741    2551.0          0.764\n32        Mid-Atlantic              New York      39827.0         52070.0   19530351   91897.0          0.433\n33      South Atlantic        North Carolina       6451.0          2817.0   10381615    9268.0          0.696\n34  West North Central          North Dakota        467.0            75.0     758080     542.0          0.862\n35  East North Central                  Ohio       6929.0          3320.0   11676341   10249.0          0.676\n36  West South Central              Oklahoma       2823.0          1048.0    3940235    3871.0          0.729\n37             Pacific                Oregon      11139.0          3337.0    4181886   14476.0          0.769\n38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   12800922   13512.0          0.604\n39         New England          Rhode Island        747.0           354.0    1058287    1101.0          0.678\n40      South Atlantic        South Carolina       3082.0           851.0    5084156    3933.0          0.784\n41  West North Central          South Dakota        836.0           323.0     878698    1159.0          0.721\n42  East South Central             Tennessee       6139.0          1744.0    6771631    7883.0          0.779\n43  West South Central                 Texas      19199.0          6111.0   28628666   25310.0          0.759\n44            Mountain                  Utah       1904.0           972.0    3153550    2876.0          0.662\n45         New England               Vermont        780.0           511.0     624358    1291.0          0.604\n46      South Atlantic              Virginia       3928.0          2047.0    8501286    5975.0          0.657\n47             Pacific            Washington      16424.0          5880.0    7523869   22304.0          0.736\n48      South Atlantic         West Virginia       1021.0           222.0    1804291    1243.0          0.821\n49  East North Central             Wisconsin       2740.0          2167.0    5807406    4907.0          0.558\n50            Mountain               Wyoming        434.0           205.0     577601     639.0          0.679\n\nAstounding column assignment! \n\nIf your dataset doesn't have the exact columns you need, you can often make your own from what you have.","metadata":{},"cell_type":"markdown","id":"d71e1aa5-15b4-42d1-8a08-4c035a6400ad"},{"source":"## Combo-attack!","metadata":{},"cell_type":"markdown","id":"50b85ddd-ceca-4008-af1a-ded5da357e50"},{"source":"**Exercise**\n\n_Combo-attack!_\n\nYou've seen the four most common types of data manipulation: \n1. sorting rows, \n2. subsetting columns, \n3. subsetting rows,\n4. adding new columns. \nIn a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.\n\nIn this exercise, you'll answer the question, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new pandas skills to find out.\n\n**Instructions**\n\n- Add a column to homelessness, indiv_per_10k, containing the number of homeless individuals per ten thousand people in each state.\n- Subset rows where indiv_per_10k is higher than 20, assigning to high_homelessness.\n- Sort high_homelessness by descending indiv_per_10k, assigning to high_homelessness_srt.\n- Select only the state and indiv_per_10k columns of high_homelessness_srt and save as result. Look at the result.\n\n#Create indiv_per_10k col as homeless individuals per 10k state pop\n\nhomelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"]\n\n#_Atencion a como lees, habias olvidado _[\"state_pop\"]\n\n#Subset rows for indiv_per_10k greater than 20\n\nhigh_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n\n#Sort high_homelessness by descending indiv_per_10k\n\nhigh_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending = False)\n\n#From high_homelessness_srt, select the state and indiv_per_10k cols\n\nresult = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n\n#When _selecting multiple columns in pandas_, you need to use double square brackets\n\n#See the result\nprint(result)\n\n                       state  indiv_per_10k\n    8   District of Columbia         53.738\n    11                Hawaii         29.079\n    4             California         27.624\n    37                Oregon         26.636\n    28                Nevada         23.314\n    47            Washington         21.829\n    32              New York         20.392\n\nCool combination! \nDistrict of Columbia has the highest number of homeless individuals - almost 54 per ten thousand people. This is almost double the number of the next-highest state, Hawaii. If you combine new column addition, row subsetting, sorting, and column selection, you can answer lots of questions like this.","metadata":{},"cell_type":"markdown","id":"0eac6554-212f-4216-bf47-6792b951855b"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}